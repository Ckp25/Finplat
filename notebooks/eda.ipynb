{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>SMA_200</th>\n",
       "      <th>...</th>\n",
       "      <th>VIX_Correlation</th>\n",
       "      <th>VIX_RelativeStrength</th>\n",
       "      <th>Avg_Market_Correlation</th>\n",
       "      <th>PE_Ratio</th>\n",
       "      <th>EPS</th>\n",
       "      <th>ROE</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>News_Volume</th>\n",
       "      <th>Sentiment_Relevance</th>\n",
       "      <th>Weighted_Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-15 00:00:00-04:00</th>\n",
       "      <td>149.680508</td>\n",
       "      <td>151.719938</td>\n",
       "      <td>148.423184</td>\n",
       "      <td>151.462540</td>\n",
       "      <td>77167900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.565181</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 00:00:00-04:00</th>\n",
       "      <td>150.640845</td>\n",
       "      <td>154.897917</td>\n",
       "      <td>150.126032</td>\n",
       "      <td>154.294006</td>\n",
       "      <td>76161100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.071280</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-17 00:00:00-04:00</th>\n",
       "      <td>154.521703</td>\n",
       "      <td>155.175117</td>\n",
       "      <td>152.739671</td>\n",
       "      <td>153.452484</td>\n",
       "      <td>98944600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.115067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.623662</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2023-03-15 00:00:00-04:00  149.680508  151.719938  148.423184  151.462540   \n",
       "2023-03-16 00:00:00-04:00  150.640845  154.897917  150.126032  154.294006   \n",
       "2023-03-17 00:00:00-04:00  154.521703  155.175117  152.739671  153.452484   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  SMA_20  SMA_50  \\\n",
       "Date                                                                           \n",
       "2023-03-15 00:00:00-04:00  77167900        0.0           0.0     NaN     NaN   \n",
       "2023-03-16 00:00:00-04:00  76161100        0.0           0.0     NaN     NaN   \n",
       "2023-03-17 00:00:00-04:00  98944600        0.0           0.0     NaN     NaN   \n",
       "\n",
       "                           SMA_200  ...  VIX_Correlation  \\\n",
       "Date                                ...                    \n",
       "2023-03-15 00:00:00-04:00      NaN  ...              NaN   \n",
       "2023-03-16 00:00:00-04:00      NaN  ...              NaN   \n",
       "2023-03-17 00:00:00-04:00      NaN  ...              NaN   \n",
       "\n",
       "                           VIX_RelativeStrength  Avg_Market_Correlation  \\\n",
       "Date                                                                      \n",
       "2023-03-15 00:00:00-04:00                   NaN                     NaN   \n",
       "2023-03-16 00:00:00-04:00              0.139199                     NaN   \n",
       "2023-03-17 00:00:00-04:00             -0.115067                     NaN   \n",
       "\n",
       "                            PE_Ratio   EPS       ROE  Sentiment_Score  \\\n",
       "Date                                                                    \n",
       "2023-03-15 00:00:00-04:00  80.565181  1.88  0.000133              0.0   \n",
       "2023-03-16 00:00:00-04:00  82.071280  1.88  0.000133              0.0   \n",
       "2023-03-17 00:00:00-04:00  81.623662  1.88  0.000133              0.0   \n",
       "\n",
       "                           News_Volume  Sentiment_Relevance  \\\n",
       "Date                                                          \n",
       "2023-03-15 00:00:00-04:00            0                  0.0   \n",
       "2023-03-16 00:00:00-04:00            0                  0.0   \n",
       "2023-03-17 00:00:00-04:00            0                  0.0   \n",
       "\n",
       "                           Weighted_Sentiment  \n",
       "Date                                           \n",
       "2023-03-15 00:00:00-04:00                 0.0  \n",
       "2023-03-16 00:00:00-04:00                 0.0  \n",
       "2023-03-17 00:00:00-04:00                 0.0  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the processed data\n",
    "df = pd.read_csv(r'D:\\Finplat\\data\\processed\\AAPL_processed_20250316.csv', index_col='Date', parse_dates=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMA_20                        19\n",
      "SMA_50                        49\n",
      "SMA_200                      199\n",
      "RSI_14                        13\n",
      "ROC_10                        10\n",
      "BB_Middle                     19\n",
      "BB_Std                        19\n",
      "BB_Upper                      19\n",
      "BB_Lower                      19\n",
      "ATR_14                        13\n",
      "S&P500_Return                  1\n",
      "S&P500_Correlation            30\n",
      "S&P500_RelativeStrength        1\n",
      "Beta_S&P500                   60\n",
      "NASDAQ_Return                  1\n",
      "NASDAQ_Correlation            30\n",
      "NASDAQ_RelativeStrength        1\n",
      "Beta_NASDAQ                   60\n",
      "DowJones_Return                1\n",
      "DowJones_Correlation          30\n",
      "DowJones_RelativeStrength      1\n",
      "Beta_DowJones                 60\n",
      "Gold_Return                    1\n",
      "Gold_Correlation              30\n",
      "Gold_RelativeStrength          1\n",
      "Oil_Return                     1\n",
      "Oil_Correlation               30\n",
      "Oil_RelativeStrength           1\n",
      "VIX_Return                     1\n",
      "VIX_Correlation               30\n",
      "VIX_RelativeStrength           1\n",
      "Avg_Market_Correlation        30\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Obtain columns with null values and the count of null values\n",
    "null_columns = df.columns[df.isnull().any()]\n",
    "print(df[null_columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Missing Values:\n",
    "1. SMA columns: The first n rows of SMAn will be NaN.The idea to handle them is to create an adaptive moving average.\n",
    "                For rows < 20, just use the closing price. For rows between 20 and 50, use SMA20.\n",
    "                For rows between 50 and 200, use SMA50, and beyond that use SMA200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>SMA_200</th>\n",
       "      <th>...</th>\n",
       "      <th>VIX_RelativeStrength</th>\n",
       "      <th>Avg_Market_Correlation</th>\n",
       "      <th>PE_Ratio</th>\n",
       "      <th>EPS</th>\n",
       "      <th>ROE</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>News_Volume</th>\n",
       "      <th>Sentiment_Relevance</th>\n",
       "      <th>Weighted_Sentiment</th>\n",
       "      <th>MA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-15 00:00:00-04:00</th>\n",
       "      <td>149.680508</td>\n",
       "      <td>151.719938</td>\n",
       "      <td>148.423184</td>\n",
       "      <td>151.46254</td>\n",
       "      <td>77167900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.565181</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.46254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low      Close  \\\n",
       "Date                                                                       \n",
       "2023-03-15 00:00:00-04:00  149.680508  151.719938  148.423184  151.46254   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  SMA_20  SMA_50  \\\n",
       "Date                                                                           \n",
       "2023-03-15 00:00:00-04:00  77167900        0.0           0.0     NaN     NaN   \n",
       "\n",
       "                           SMA_200  ...  VIX_RelativeStrength  \\\n",
       "Date                                ...                         \n",
       "2023-03-15 00:00:00-04:00      NaN  ...                   NaN   \n",
       "\n",
       "                           Avg_Market_Correlation   PE_Ratio   EPS       ROE  \\\n",
       "Date                                                                           \n",
       "2023-03-15 00:00:00-04:00                     NaN  80.565181  1.88  0.000133   \n",
       "\n",
       "                           Sentiment_Score  News_Volume  Sentiment_Relevance  \\\n",
       "Date                                                                           \n",
       "2023-03-15 00:00:00-04:00              0.0            0                  0.0   \n",
       "\n",
       "                           Weighted_Sentiment         MA  \n",
       "Date                                                      \n",
       "2023-03-15 00:00:00-04:00                 0.0  151.46254  \n",
       "\n",
       "[1 rows x 58 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_adaptive_ma(df):\n",
    "    # Start with a column filled with the closing price\n",
    "    df['MA'] = df['Close'].copy()\n",
    "    \n",
    "    # Update values as moving averages become available\n",
    "    # For days where SMA_20 is available\n",
    "    mask_sma20 = df['SMA_20'].notna()\n",
    "    df.loc[mask_sma20, 'MA'] = df.loc[mask_sma20, 'SMA_20']\n",
    "    \n",
    "    # For days where SMA_50 is available, override with SMA_50\n",
    "    mask_sma50 = df['SMA_50'].notna()\n",
    "    df.loc[mask_sma50, 'MA'] = df.loc[mask_sma50, 'SMA_50']\n",
    "    \n",
    "    # For days where SMA_200 is available, override with SMA_200\n",
    "    mask_sma200 = df['SMA_200'].notna()\n",
    "    df.loc[mask_sma200, 'MA'] = df.loc[mask_sma200, 'SMA_200']\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = create_adaptive_ma(df)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop SMA columns\n",
    "df.drop(columns=['SMA_20', 'SMA_50', 'SMA_200'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Handling the RSI_14 and ROC_10 features: Missing values in RSI_14 can be filled with a neutral value of 50.\n",
    "                                            Missing values in ROC_10 can be filled with no change assumption and fill in 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RSI_14'] = df['RSI_14'].fillna(50)\n",
    "df['ROC_10'] = df['ROC_10'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Handling the BB Columns: Using a similar adaptive method like SMAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the price for BB_Middle\n",
    "df['Adaptive_BB_Middle'] = df['Close'].copy()\n",
    "\n",
    "# Once BB_Middle is available, use that\n",
    "mask = df['BB_Middle'].notna()\n",
    "df.loc[mask, 'Adaptive_BB_Middle'] = df.loc[mask, 'BB_Middle']\n",
    "\n",
    "# For standard deviation, start with a small fixed value (e.g., 1% of price)\n",
    "df['Adaptive_BB_Std'] = df['Close'] * 0.01  # 1% of price as initial volatility\n",
    "\n",
    "# Once actual BB_Std is available, use that\n",
    "mask = df['BB_Std'].notna()\n",
    "df.loc[mask, 'Adaptive_BB_Std'] = df.loc[mask, 'BB_Std']\n",
    "\n",
    "# Calculate adaptive bands\n",
    "df['Adaptive_BB_Upper'] = df['Adaptive_BB_Middle'] + (df['Adaptive_BB_Std'] * 2)\n",
    "df['Adaptive_BB_Lower'] = df['Adaptive_BB_Middle'] - (df['Adaptive_BB_Std'] * 2)\n",
    "\n",
    "# Normalized BB width (volatility measure)\n",
    "df['BB_Width'] = (df['Adaptive_BB_Upper'] - df['Adaptive_BB_Lower']) / df['Adaptive_BB_Middle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop BB columns\n",
    "df.drop(columns=['BB_Middle', 'BB_Std', 'BB_Upper','BB_Lower'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Handling AIR_14 column: Adaptive AIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate True Range (TR) first\n",
    "\n",
    "# Fill NaN values in the shifted column first\n",
    "shifted_close = df['Close'].shift(1)\n",
    "shifted_close.iloc[0] = df['Close'].iloc[0]  # Just use the first day's close\n",
    "\n",
    "high_low = df['High'] - df['Low']\n",
    "high_close = (df['High'] - shifted_close).abs()\n",
    "low_close = (df['Low'] - shifted_close).abs()\n",
    "tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "\n",
    "\n",
    "# First row of TR will be NaN because of the shift operation\n",
    "# Fill it with the day's high-low range\n",
    "#Get the first row's index value properly\n",
    "first_index = df.index[0]\n",
    "\n",
    "df['TR'] = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "first_index = df.index[0]\n",
    "df.loc[first_index, 'TR'] = df.loc[first_index, 'High'] - df.loc[first_index, 'Low']\n",
    "\n",
    "# 2. Fix the ATR calculation using the correct indexing\n",
    "df['Adaptive_ATR'] = df['TR'].copy()  # Start with TR\n",
    "\n",
    "# Now use that index value to set the TR for the first row\n",
    "df.loc[first_index, 'TR'] = df.loc[first_index, 'High'] - df.loc[first_index, 'Low']\n",
    "\n",
    "\n",
    "for i, (idx, _) in enumerate(df.iterrows()):\n",
    "    if i > 0:  # Skip first row\n",
    "        lookback = min(i+1, 14)\n",
    "        start_idx = i-lookback+1\n",
    "        df.loc[idx, 'Adaptive_ATR'] = df['TR'].iloc[start_idx:i+1].mean()\n",
    "\n",
    "\n",
    "# Once ATR_14 is available, use that\n",
    "mask = df['ATR_14'].notna()\n",
    "df.loc[mask, 'Adaptive_ATR'] = df.loc[mask, 'ATR_14']\n",
    "\n",
    "# Normalize ATR as percentage of price\n",
    "df['Adaptive_ATR_Pct'] = df['Adaptive_ATR'] / df['Close'] * 100\n",
    "\n",
    "\n",
    "# Drop ATR column\n",
    "df.drop('ATR_14', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Handling SP features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['S&P500_Price'] = df['S&P500_Price'].fillna(method='ffill')\n",
    "df['S&P500_Return'] = df['S&P500_Return'].fillna(0)\n",
    "# Forward fill (use previous valid value)\n",
    "df['S&P500_Correlation'] = df['S&P500_Correlation'].fillna(method='ffill')\n",
    "\n",
    "# If missing at the start, then backfill those initial points\n",
    "df['S&P500_Correlation'] = df['S&P500_Correlation'].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Fill\n",
    "df['Beta_S&P500'] = df['Beta_S&P500'].fillna(method='ffill')\n",
    "sector_avg_beta = 1.2 \n",
    "df['Beta_S&P500'] = df['Beta_S&P500'].fillna(sector_avg_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate all relative strength values to ensure consistency\n",
    "df['S&P500_RelativeStrength'] = df['Close'] / df['S&P500_Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Approach is same for Dow Jones and NASDAQ features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NASDAQ_Return'] = df['NASDAQ_Return'].fillna(0)\n",
    "# Forward fill (use previous valid value)\n",
    "df['NASDAQ_Correlation'] = df['NASDAQ_Correlation'].fillna(method='ffill')\n",
    "\n",
    "# If missing at the start, then backfill those initial points\n",
    "df['NASDAQ_Correlation'] = df['NASDAQ_Correlation'].fillna(method='bfill')\n",
    "\n",
    "# Forward Fill\n",
    "df['Beta_NASDAQ'] = df['Beta_NASDAQ'].fillna(method='ffill')\n",
    "sector_avg_beta = 1.2 \n",
    "df['Beta_NASDAQ'] = df['Beta_NASDAQ'].fillna(sector_avg_beta)\n",
    "\n",
    "df['NASDAQ_RelativeStrength'] = df['Close'] / df['NASDAQ_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all market indices/assets you're tracking\n",
    "markets = ['DowJones', 'Gold', 'Oil', 'VIX']\n",
    "\n",
    "# Process each market's columns\n",
    "for market in markets:\n",
    "    # Handle Price columns (forward fill is most appropriate)\n",
    "    df[f'{market}_Price'] = df[f'{market}_Price'].fillna(method='ffill')\n",
    "    \n",
    "    # Handle Return columns (can be recalculated from prices if needed)\n",
    "    missing_returns = df[f'{market}_Return'].isna()\n",
    "    if missing_returns.any() and not df[f'{market}_Price'].isna().all():\n",
    "        # Calculate returns for missing data points if we have the prices\n",
    "        temp_returns = df[f'{market}_Price'].pct_change()\n",
    "        df.loc[missing_returns, f'{market}_Return'] = temp_returns[missing_returns]\n",
    "    # Fill any remaining NaNs with zeros or forward fill\n",
    "    df[f'{market}_Return'] = df[f'{market}_Return'].fillna(0)\n",
    "    \n",
    "    # Handle Correlation (forward fill is appropriate)\n",
    "    df[f'{market}_Correlation'] = df[f'{market}_Correlation'].fillna(method='ffill')\n",
    "    # If missing at the start, then backfill those initial points\n",
    "    df[f'{market}_Correlation'] = df[f'{market}_Correlation'].fillna(method='bfill')\n",
    "    # If missing at the start, then backfill those initial points\n",
    "    # Handle RelativeStrength (recalculate where possible)\n",
    "    missing_rs = df[f'{market}_RelativeStrength'].isna()\n",
    "    if missing_rs.any() and not df[f'{market}_Price'].isna().all():\n",
    "        df.loc[missing_rs, f'{market}_RelativeStrength'] = df.loc[missing_rs, 'Close'] / df.loc[missing_rs, f'{market}_Price']\n",
    "    # Forward fill any remaining\n",
    "    df[f'{market}_RelativeStrength'] = df[f'{market}_RelativeStrength'].fillna(method='ffill')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Forward Fill\n",
    "df['Beta_DowJones'] = df['Beta_DowJones'].fillna(method='ffill')\n",
    "sector_avg_beta = 1.2 \n",
    "df['Beta_DowJones'] = df['Beta_DowJones'].fillna(sector_avg_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill (use previous valid value)\n",
    "df['Avg_Market_Correlation'] = df['Avg_Market_Correlation'].fillna(method='ffill')\n",
    "\n",
    "# If missing at the start, then backfill those initial points\n",
    "df['Avg_Market_Correlation'] = df['Avg_Market_Correlation'].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "# Recheck for missing values\n",
    "null_columns = df.columns[df.isnull().any()]\n",
    "print(df[null_columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to D:\\Finplat\\data\\processed\\AAPL_processed_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Make a csv file to store the modified dataframe\n",
    "output_path = 'D:\\\\Finplat\\\\data\\\\processed\\\\AAPL_processed_clean.csv'\n",
    "df.to_csv(output_path, \n",
    "          index=True,           # Keep the date index\n",
    "          float_format='%.4f',  # Limit decimal places for floats\n",
    "          encoding='utf-8')     # Specify encoding\n",
    "\n",
    "print(f\"Cleaned data saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
